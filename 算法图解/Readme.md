# 算法图解

## 内容Map

- 二分算法
- 大O表示法
- 旅行商问题
- 数组与链表
- 排序算法
- 递归

## 笔记整理

### 二分算法

二分查找是一种算法，其输入是一个有序的元素列表。如果要查找的元素包含在列表中，二分查找返回其位置；否则返回`null`。

对于一个有`n`个元素的有序数组，简单查找最多需要`n`步，而二分查找最多需要`log2n`向下取整再`+1`步。如果要查找的元素存在于有序数组中，且不为结尾的边界元素，则最多只需要`log2n`步；如果要查找的元素不存在于有序数组中，或是有序数组结尾的元素，则最多需要`log2n`向下取整再`+1`步。

简单查找的运行时间为线性时间，时间复杂度为`O(n)`，二分查找的运行时间为对数时间（或`log`时间），时间复杂度为`O(logn)`。

### 大O表示法

大O表示法除了用于预估一个算法需要多长时间才能运行完毕，还能够用于预估运行时间如何随列表增长而增加。大O表示法，O后边的括号中是操作数。

一些很常见的大O运行时间有：`O(logn)`、`O(n)`、`O(n*logn)`、`O(n^2)`、`O(n!)`。

算法的速度指的并非时间，而是操作数的增速。谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以什么样的速度增加，即是从其增速的角度度量。

算法的运行时间用大O表示法表示，大O表示法指出的是最糟糕的情况。

### 旅行商问题

一位旅行商要前往`n`个城市，现要考虑前往这`n`个城市的各种顺序（正向顺序和逆向顺序算两次），需要执行`n!`次操作才能计算出结果，因此此算法的时间复杂度为`O(n!)`。这是计算机科学领域待解的问题之一。对于这个问题，目前还没有找到更快的算法，有些很聪明的人认为这个问题根本就没有更巧妙的算法。面对这个问题，我们能做的只是去找出近似答案。

旅行商问题实际上是排列组合中的排列问题。排列组合是组合学最基本的概念。所谓排列，就是指从给定个数的元素中取出指定个数的元素进行排序。组合则是指从给定个数的元素中仅仅取出指定个数的元素，不考虑排序。

#### 排列

排列的定义：从`n`个不同元素中，任取`m`(`m≤n`,`m`与`n`均为自然数,下同）个不同的元素按照一定的顺序排成一列，叫做从`n`个不同元素中取出m个元素的一个排列；从`n`个不同元素中取出`m`（`m≤n`）个元素的所有排列的个数，叫做从`n`个不同元素中取出`m`个元素的排列数，用符号`A(n,m)`表示。

计算公式：

![排列计算公式](https://pic2.superbed.cn/item/5dc3ca678e0e2e3ee9582676.jpg)

此外，**规定`0! = 1`**。

因此，旅行商问题即为从`n`个元素中取`n`个元素进行排列的问题，按上述公式，即`n=m`，因此可推导得出`A(n,n) = n! / 0! = n! / 1 = n!`。

#### 组合

组合的定义：从`n`个不同元素中，任取`m`（`m≤n`）个元素并成一组，叫做从`n`个不同元素中取出`m`个元素的一个组合；从`n`个不同元素中取出`m`（`m≤n`）个元素的所有组合的个数，叫做从`n`个不同元素中取出`m`个元素的组合数。用符号`C(n,m)`表示。

计算公式：

![组合计算公式](https://pic2.superbed.cn/item/5dc3ccae8e0e2e3ee95853c8.jpg)

### 数组与链表

数组的读取复杂度为`O(1)`（常量时间），插入、删除复杂度为`O(n)`（线性时间）；链表的读取复杂度为`O(n)`（线性时间），插入、删除复杂度为`O(1)`（常量时间）。

向数组添加元素，如果发现连续可用内存不足，会在内存中将数组整体迁移，因此数组新增元素的速度会很慢。如果是静态语言，可以选择为数组预留长度的方式，但这种方式的两个弊端是：`预留的空间如果没有使用是种浪费`、`如果预留的空间不足，还是要整体迁移`。动态语言速度上慢于静态语言的一点原因是，诸如数组等数据类型，动态语言并没有要求必须确认长度，而在计算机内部，内存的分配是一定的，因此动态语言中这部分工作都交给了解释器执行，这一步是需要消耗时间的。

数组的下标从零开始有一种思路：将这个下标看作相对于数组第一个元素的偏移量。则第一个元素相对于自身偏移量为`0`，第二个为`1`，依次类推。

#### 数组链表

来自Facebook用户名存储案例，具体如下：

  实际上，Facebook存储用户信息时使用的既不是数组也不是链表。假设Facebook使用的是一种混合数据：链表数组。这个数组包含26个元素，每个元素都指向一个链表。例如，该数组的第一个元素指向的链表包含所有以A打头的用户名，第二个元素指向的链表包含所有以B打头的用户名，以此类推。

数组链表综合了数组和链表的优点：

1. 因为数组长度固定，不用担心会发生数组迁移
2. 因为数组内容有序，可以使用二分法查找首字母
3. 因为某一首字母下的用户名使用链表存储，插入和删除比数组快得多

数组链表与数组相比：查找比数组慢（因为还要查链表），但插入比数组快（因为无需元素迁移）；数组链表与链表相比：查找比链表快（因为可以借助数组缩小查询范围，并且查询数组时可以使用二分算法），如果不考虑插入前的查找工作，则插入同链表速度差不多（因为都是链表的插入）、如果考虑插入前的查找工作，则插入比链表快（因为需要被查询的链表元素少了）。

#### 想法

可以借助一个键值对map保存字母与数组下标的对应关系，因为26个字母是有序的。这样通过空间换取了二分法查找数组的时间`O(logn)`，查找时间仅需`O(1)`。

### 排序算法

#### 选择排序（Selection Sort）

现有无序数组A，要对A进行从大到小的排序。选择排序方法是先新建一个数组B，然后开始进行排序：遍历A，找到A中此时最大的值，将此值推入B，并在A中剔除，然后再次上述操作，直到所有的元素都被处理完毕。

选择排序是一种灵巧的算法（虽然我没看出来哪里灵巧），但它速度较慢。对于A中的每一个元素都要遍历一遍整个数组（平均每次要遍历`n/2`个元素），A中共有`n`个元素，因此要执行`n`此遍历，则其时间复杂度为`O(n^2)`（其实应该是`O(n^2/2)`，但类似二分之一之类的常数在大O表示法中会被忽略不计）。

#### 快速排序（Quick Sort）

基线条件：对于包含0个或1个元素的数组，原样返回即可，无需排序；
归纳条件：对于包含多个元素的数组，选择某一元素作为基线值，将数组划分为 `[小于基线值的元素集合], [基线值元素], [大于基线值的元素集合]`三个子数组，对于长度大于1的子数组再次执行快速排序，最后将结果拼接即可得到排序结果。

比选择排序快得多，C语言标准库函数中的`qsort`使用快速排序原理。

快速排序速度受基准值选择的影响，如果基准值选择的足够理想，则每次基准值两边的子数组都能等分，从而减少快排次数，理想情况下，快速排序算法时间复杂度为`O(nlogn)`；而如果基准值选择恰好是极端情况，比如最极端的，每次选择的基准值都是整个数组中的最大值，则每次小于基准值的数组长度都是`此次操作数组的长度-1`，此时快速排序相当于每次都排好一个值，对于长度为n的数组来说，需要执行n次快速排序操作，每次操作都需要从本次操作数组中取出一个基准值并将本次操作数组中的每个元素同基准值比较一次大小，因此此时快速排序算法整体时间复杂度会达到`O(n^2)`，等同于选择排序。

结合D&C与归纳证明思想，得证快速排序方法有效。

#### 合并排序/归并排序（Merge Sort）

![合并排序](https://pic1.superbed.cn/item/5dfb294376085c3289c55a44.jpg)

比起快速排序时间复杂度受基准值选择的影响导致不够稳定，合并排序的时间复杂度更为稳定，速度仅次于快速排序，为`O(nlogn)`。

归并操作的工作原理如下：

第一步：申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列

第二步：设定两个指针，最初位置分别为两个已经排序序列的起始位置

第三步：比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置

重复步骤3直到某一指针超出序列尾

将另一序列剩下的所有元素直接复制到合并序列尾

### 递归

每个递归函数都有两部分：基线条件（`base case`）和递归条件（`recursive case`）。递归条件指的是函数调用自己，而基线条件则指的是函数不再调用自己，从而避免形成无限循环。

递归只是让解决方案更清晰，并没有性能上的优势。实际上，在有些情况下，使用循环的性能更好。

#### 尾递归

如果一个函数中所有递归形式的调用都出现在函数的末尾，我们称这个递归函数是尾递归的。当递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分时，这个递归调用就是尾递归。尾递归函数的特点是在回归过程中不用做任何操作，这个特性很重要，因为大多数现代的编译器会利用这种特点自动生成优化的代码。尾递归的优化原理是：当编译器检测到一个函数调用是尾递归的时候，它就覆盖当前的活动记录而不是在栈中去创建一个新的。编译器可以做到这点，因为递归调用是当前活跃期内最后一条待执行的语句，于是当这个调用返回时栈帧中并没有其他事情可做，因此也就没有保存栈帧的必要了。通过覆盖当前的栈帧而不是在其之上重新添加一个，这样所使用的栈空间就大大缩减了，这使得实际的运行效率会变得更高。

简单地说，尾递归函数的最后一步是执行一个函数。用阶乘举例，普通递归写法如下：

```js
function fac(n) {
  if (n === 1) return 1;
  return n * fac(n - 1);
}

fac(5) // 120
```

尾递归写法如下：

```js
function fac(n, total) {
  if (n === 1) return total;
  return fac(n - 1, n * total);
}

fac(5, 1) // 120
```

调用函数会产生一个调用记录，而尾递归中永远只有一个调用记录，最后一步操作`return fac(n - 1, n * total)`把当前函数的计算结果当做参数传递给了下一个自身调用，这样第一个函数调用产生的调用记录就消失了，因为它执行完了。

并不是所有的语言都支持尾递归优化，但es6已经添加了对尾递归优化的支持，但ES6的尾调用优化只在严格模式下开启，正常模式是无效的。这是因为在正常模式下，函数内部有两个变量，可以跟踪函数的调用栈：

- `func.arguments`：返回调用时函数的参数
- `func.caller`：返回调用当前函数的那个函数

尾调用优化发生时，函数的调用栈会改写，因此上面两个变量就会失真。严格模式禁用这两个变量，所以尾调用模式仅在严格模式下生效。

### 分而治之

D&C的工作原理：

1. 找出简单的基线条件；
2. 确定如何缩小问题的规模，使其符合基线条件。

D&C并非可用于解决问题的算法，而是一种解决问题的思路。

分治方法（Divide and Conquer）分三个步骤：

1. Divide：将原问题分解为若干子问题，其中这些子问题的规模小于原问题的规模。

2. Conquer：递归地求解子问题，当子问题规模足够小时直接求解。

3. Merge：将子问题的解合并得到原问题的解。

快速排序、归并排序就是很标准的按照上述三个步骤进行的。

### 数组元素操作方法整理

- `push()`：在数组的末尾添加一个或多个元素 返回数组新长度

- `pop()`：移除数组的最后一项，返回移除的项

- `unshift()`:在数组的第一项前面添加一个或多个元素，返回数组新长度

- `shift()`：移除数组的第一项，返回移除项

移除元素的方法返回移除的项，添加元素的方法返回数组新长度。

### 散列表

#### 关于冲突

散列表冲突也就是hash冲突，是不可避免的，需要思考的就是怎么有针对性的在应用场景中选择性能最好的解决方案。Java中Hashmap解决哈希碰撞也是随着Java版本升级在变，Java8中使用红黑树的解决方案还是值得借鉴的。

#### 避免冲突

散列表要避免冲突需要：

- 较低的填装因子
- 良好的散列函数

其中，`填装因子=存储的数据量/存储空间`，值越小，冲突越小。如果值超过一定阈值，需要增大存储空间，伴随着开链表。

#### 解决冲突

如果不可避免地产生了冲突，有以下三种解决方式：

1. 开放定址法：寻找下一个没有被索性占用的空间
2. 链地址法：将这个索性的空间变成链表进行存储
3. 双重散列（Double Hashing），即不仅使用一个散列函数，而使用一组散列函数hash1(key), hash2(key), hash3(key)等等。先用第一个散列函数， 如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置为止

#### 应用实例

DNS解析服务器要将海量网址映射到相应的ip地址，散列表是提供这种功能的方式之一。电脑经常出现无效的DNS解析，就是DNS域名解析服务器出现了故障。

#### 关于散列表平均情况和最糟情况速度差别巨大的看法（摘自他人想法）

算法的优劣和意义在数据量小时没有太大差别，甚至好的算法还会更慢，但是一旦数据量猛增到一定程度，任何微小的变化都会造成极大的差异。放在个人身上也是如此，任何事情，在早期的发展阶段，人与人之间的差异非常小，于是我们就会有种错觉，让我们误以为大家都一样，但实际上方法论和底层思维框架会在时间的作用下让两者造成巨大的差异。


#### 底层原理

散列表随机存取的特性要求必须散列表的实现必须使用数组而不能使用链表。

数据结构中将散列存储单独归为一类存储结构，散列表是一种包含额外逻辑的数据结构。